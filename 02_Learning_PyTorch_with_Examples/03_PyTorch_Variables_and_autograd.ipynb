{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "origin: http://pytorch.org/tutorials/beginner/pytorch_with_examples.html  \n",
    "translator: Hongpu Liu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Variables和autograd实现\n",
    "在前面的例子中，不得不手工实现了神经网络的前馈和反馈过程。手动实现反向传播过程对于两层网络并不是大问题，但是对于巨大复杂的网络却非常困难。\n",
    "\n",
    "幸运的是，可以使用**自动微分**来自动计算神经网络中的反向传播。PyTorch中的**autograd**包就是用来实现这一功能的。当使用**autograd**时，网络的前馈传播将定义一个**计算图**：节点是**Tensor**，边则是函数，这些函数可以根据输入张量来计算输出张量。在反向传播的过程中，可以沿着图计算梯度。\n",
    "\n",
    "**autograd**的机制看上去非常复杂，但是在实践中非常简单。首先将**Tensor**封装到一个**Variable**对象中，该对象表示计算图中的节点。若**x**是一个Variable，则**x.data**是一个Tensor，而**x.grad**是一个Variable，它封装了对某个标量值对**x**的梯度。\n",
    "\n",
    "PyTorch中**Variables**与**Tensor**有着（几乎）相同的API：任何对**Tensor**可用的操作，对**Variable**同样有效。它们之间的差别是：使用**Variable**会创建一个计算图，以自动计算梯度。\n",
    "\n",
    "接下来利用PyTorch的**Variable**和**autograd**来实现一个两层网络，现在不再需要手动实现反向传播过程了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 29932376.0)\n",
      "(1, 29294076.0)\n",
      "(2, 36446632.0)\n",
      "(3, 45305572.0)\n",
      "(4, 46360520.0)\n",
      "(5, 33209082.0)\n",
      "(6, 16061441.0)\n",
      "(7, 6098585.5)\n",
      "(8, 2558574.25)\n",
      "(9, 1456576.625)\n",
      "(10, 1052032.875)\n",
      "(11, 844920.4375)\n",
      "(12, 705686.8125)\n",
      "(13, 598862.75)\n",
      "(14, 512707.09375)\n",
      "(15, 441789.125)\n",
      "(16, 382639.8125)\n",
      "(17, 332916.53125)\n",
      "(18, 290848.40625)\n",
      "(19, 255124.78125)\n",
      "(20, 224624.109375)\n",
      "(21, 198433.015625)\n",
      "(22, 175851.140625)\n",
      "(23, 156314.453125)\n",
      "(24, 139355.609375)\n",
      "(25, 124567.84375)\n",
      "(26, 111636.9140625)\n",
      "(27, 100288.6015625)\n",
      "(28, 90298.890625)\n",
      "(29, 81483.1796875)\n",
      "(30, 73685.0)\n",
      "(31, 66782.640625)\n",
      "(32, 60633.3125)\n",
      "(33, 55149.42578125)\n",
      "(34, 50247.33984375)\n",
      "(35, 45855.9296875)\n",
      "(36, 41913.38671875)\n",
      "(37, 38369.75390625)\n",
      "(38, 35174.89453125)\n",
      "(39, 32290.1171875)\n",
      "(40, 29680.140625)\n",
      "(41, 27315.251953125)\n",
      "(42, 25168.70703125)\n",
      "(43, 23216.703125)\n",
      "(44, 21438.490234375)\n",
      "(45, 19816.439453125)\n",
      "(46, 18334.92578125)\n",
      "(47, 16979.60546875)\n",
      "(48, 15738.0791015625)\n",
      "(49, 14599.4638671875)\n",
      "(50, 13553.9228515625)\n",
      "(51, 12593.0498046875)\n",
      "(52, 11708.9072265625)\n",
      "(53, 10894.3173828125)\n",
      "(54, 10143.1435546875)\n",
      "(55, 9449.8818359375)\n",
      "(56, 8809.560546875)\n",
      "(57, 8217.412109375)\n",
      "(58, 7669.32080078125)\n",
      "(59, 7161.5107421875)\n",
      "(60, 6690.8984375)\n",
      "(61, 6254.3056640625)\n",
      "(62, 5849.0322265625)\n",
      "(63, 5472.6982421875)\n",
      "(64, 5122.72900390625)\n",
      "(65, 4797.20751953125)\n",
      "(66, 4494.2373046875)\n",
      "(67, 4212.1611328125)\n",
      "(68, 3949.29638671875)\n",
      "(69, 3704.19384765625)\n",
      "(70, 3475.61962890625)\n",
      "(71, 3262.265625)\n",
      "(72, 3063.08154296875)\n",
      "(73, 2877.0146484375)\n",
      "(74, 2703.19580078125)\n",
      "(75, 2540.723388671875)\n",
      "(76, 2388.618408203125)\n",
      "(77, 2246.3076171875)\n",
      "(78, 2113.08544921875)\n",
      "(79, 1988.3494873046875)\n",
      "(80, 1871.55517578125)\n",
      "(81, 1762.09765625)\n",
      "(82, 1659.521484375)\n",
      "(83, 1563.2852783203125)\n",
      "(84, 1473.004150390625)\n",
      "(85, 1388.2640380859375)\n",
      "(86, 1308.7254638671875)\n",
      "(87, 1234.0428466796875)\n",
      "(88, 1163.875732421875)\n",
      "(89, 1097.953125)\n",
      "(90, 1035.9945068359375)\n",
      "(91, 977.7432861328125)\n",
      "(92, 922.95556640625)\n",
      "(93, 871.4264526367188)\n",
      "(94, 822.9425659179688)\n",
      "(95, 777.3302612304688)\n",
      "(96, 734.3916625976562)\n",
      "(97, 693.9486694335938)\n",
      "(98, 655.8493041992188)\n",
      "(99, 619.9525756835938)\n",
      "(100, 586.134765625)\n",
      "(101, 554.2656860351562)\n",
      "(102, 524.2164306640625)\n",
      "(103, 495.8902587890625)\n",
      "(104, 469.1819763183594)\n",
      "(105, 443.9798583984375)\n",
      "(106, 420.2089538574219)\n",
      "(107, 397.7710876464844)\n",
      "(108, 376.5956115722656)\n",
      "(109, 356.62066650390625)\n",
      "(110, 337.7599182128906)\n",
      "(111, 319.9452819824219)\n",
      "(112, 303.1164245605469)\n",
      "(113, 287.2180480957031)\n",
      "(114, 272.1961364746094)\n",
      "(115, 257.99554443359375)\n",
      "(116, 244.5763702392578)\n",
      "(117, 231.88746643066406)\n",
      "(118, 219.8856964111328)\n",
      "(119, 208.54161071777344)\n",
      "(120, 197.81155395507812)\n",
      "(121, 187.65440368652344)\n",
      "(122, 178.0424346923828)\n",
      "(123, 168.94627380371094)\n",
      "(124, 160.33506774902344)\n",
      "(125, 152.18443298339844)\n",
      "(126, 144.46836853027344)\n",
      "(127, 137.157470703125)\n",
      "(128, 130.23663330078125)\n",
      "(129, 123.68217468261719)\n",
      "(130, 117.47187805175781)\n",
      "(131, 111.58644104003906)\n",
      "(132, 106.0080795288086)\n",
      "(133, 100.71990966796875)\n",
      "(134, 95.70722961425781)\n",
      "(135, 90.95654296875)\n",
      "(136, 86.45211029052734)\n",
      "(137, 82.17801666259766)\n",
      "(138, 78.12399291992188)\n",
      "(139, 74.27979278564453)\n",
      "(140, 70.63298797607422)\n",
      "(141, 67.17205810546875)\n",
      "(142, 63.889827728271484)\n",
      "(143, 60.77302932739258)\n",
      "(144, 57.81315994262695)\n",
      "(145, 55.0045166015625)\n",
      "(146, 52.336944580078125)\n",
      "(147, 49.804473876953125)\n",
      "(148, 47.40187072753906)\n",
      "(149, 45.11672592163086)\n",
      "(150, 42.94708251953125)\n",
      "(151, 40.8852424621582)\n",
      "(152, 38.927085876464844)\n",
      "(153, 37.06472396850586)\n",
      "(154, 35.29600143432617)\n",
      "(155, 33.61503219604492)\n",
      "(156, 32.01590347290039)\n",
      "(157, 30.496225357055664)\n",
      "(158, 29.050899505615234)\n",
      "(159, 27.67750358581543)\n",
      "(160, 26.370677947998047)\n",
      "(161, 25.127960205078125)\n",
      "(162, 23.9453125)\n",
      "(163, 22.82038116455078)\n",
      "(164, 21.750099182128906)\n",
      "(165, 20.73263168334961)\n",
      "(166, 19.764610290527344)\n",
      "(167, 18.842090606689453)\n",
      "(168, 17.96472930908203)\n",
      "(169, 17.129169464111328)\n",
      "(170, 16.33405113220215)\n",
      "(171, 15.577059745788574)\n",
      "(172, 14.85610294342041)\n",
      "(173, 14.169808387756348)\n",
      "(174, 13.515686988830566)\n",
      "(175, 12.892967224121094)\n",
      "(176, 12.299901962280273)\n",
      "(177, 11.735374450683594)\n",
      "(178, 11.197096824645996)\n",
      "(179, 10.684126853942871)\n",
      "(180, 10.19582748413086)\n",
      "(181, 9.729820251464844)\n",
      "(182, 9.286304473876953)\n",
      "(183, 8.863354682922363)\n",
      "(184, 8.460494041442871)\n",
      "(185, 8.076155662536621)\n",
      "(186, 7.7099504470825195)\n",
      "(187, 7.360565662384033)\n",
      "(188, 7.027680397033691)\n",
      "(189, 6.710312366485596)\n",
      "(190, 6.407621383666992)\n",
      "(191, 6.118793487548828)\n",
      "(192, 5.843300819396973)\n",
      "(193, 5.58065128326416)\n",
      "(194, 5.329772472381592)\n",
      "(195, 5.090904712677002)\n",
      "(196, 4.862799167633057)\n",
      "(197, 4.64511251449585)\n",
      "(198, 4.43739652633667)\n",
      "(199, 4.23911714553833)\n",
      "(200, 4.0503435134887695)\n",
      "(201, 3.8699235916137695)\n",
      "(202, 3.697500705718994)\n",
      "(203, 3.5334043502807617)\n",
      "(204, 3.3763272762298584)\n",
      "(205, 3.226475477218628)\n",
      "(206, 3.0835447311401367)\n",
      "(207, 2.9473228454589844)\n",
      "(208, 2.816882610321045)\n",
      "(209, 2.6923165321350098)\n",
      "(210, 2.573514938354492)\n",
      "(211, 2.4599599838256836)\n",
      "(212, 2.351785898208618)\n",
      "(213, 2.248335361480713)\n",
      "(214, 2.1493186950683594)\n",
      "(215, 2.054912567138672)\n",
      "(216, 1.9646629095077515)\n",
      "(217, 1.8786096572875977)\n",
      "(218, 1.7963076829910278)\n",
      "(219, 1.717427134513855)\n",
      "(220, 1.6423176527023315)\n",
      "(221, 1.5706233978271484)\n",
      "(222, 1.502065658569336)\n",
      "(223, 1.436513900756836)\n",
      "(224, 1.3739979267120361)\n",
      "(225, 1.3141570091247559)\n",
      "(226, 1.2568235397338867)\n",
      "(227, 1.202141284942627)\n",
      "(228, 1.1498339176177979)\n",
      "(229, 1.1000503301620483)\n",
      "(230, 1.0522644519805908)\n",
      "(231, 1.0065335035324097)\n",
      "(232, 0.9629661440849304)\n",
      "(233, 0.921368420124054)\n",
      "(234, 0.8814907670021057)\n",
      "(235, 0.8433969020843506)\n",
      "(236, 0.8068430423736572)\n",
      "(237, 0.7721669673919678)\n",
      "(238, 0.7387311458587646)\n",
      "(239, 0.7069390416145325)\n",
      "(240, 0.6764513850212097)\n",
      "(241, 0.6473291516304016)\n",
      "(242, 0.6194792985916138)\n",
      "(243, 0.5928213000297546)\n",
      "(244, 0.5673800706863403)\n",
      "(245, 0.5429680347442627)\n",
      "(246, 0.5196497440338135)\n",
      "(247, 0.49735331535339355)\n",
      "(248, 0.47602778673171997)\n",
      "(249, 0.45563310384750366)\n",
      "(250, 0.43612316250801086)\n",
      "(251, 0.4174294173717499)\n",
      "(252, 0.3995381295681)\n",
      "(253, 0.3824087679386139)\n",
      "(254, 0.36610928177833557)\n",
      "(255, 0.35047972202301025)\n",
      "(256, 0.33548876643180847)\n",
      "(257, 0.3211604058742523)\n",
      "(258, 0.30745604634284973)\n",
      "(259, 0.2943226993083954)\n",
      "(260, 0.28182080388069153)\n",
      "(261, 0.26983076333999634)\n",
      "(262, 0.2583320736885071)\n",
      "(263, 0.2472952902317047)\n",
      "(264, 0.2367808073759079)\n",
      "(265, 0.22677214443683624)\n",
      "(266, 0.21713173389434814)\n",
      "(267, 0.20790350437164307)\n",
      "(268, 0.1990233212709427)\n",
      "(269, 0.19058848917484283)\n",
      "(270, 0.1825176626443863)\n",
      "(271, 0.17476259171962738)\n",
      "(272, 0.1673637181520462)\n",
      "(273, 0.16028369963169098)\n",
      "(274, 0.15351703763008118)\n",
      "(275, 0.1470363289117813)\n",
      "(276, 0.14076478779315948)\n",
      "(277, 0.13487547636032104)\n",
      "(278, 0.1291283220052719)\n",
      "(279, 0.12369746714830399)\n",
      "(280, 0.11846589297056198)\n",
      "(281, 0.11343898624181747)\n",
      "(282, 0.10867774486541748)\n",
      "(283, 0.10409362614154816)\n",
      "(284, 0.09969279915094376)\n",
      "(285, 0.09550942480564117)\n",
      "(286, 0.0914631187915802)\n",
      "(287, 0.08761876076459885)\n",
      "(288, 0.08390645682811737)\n",
      "(289, 0.08038101345300674)\n",
      "(290, 0.0770084485411644)\n",
      "(291, 0.07377621531486511)\n",
      "(292, 0.07063806056976318)\n",
      "(293, 0.0676996260881424)\n",
      "(294, 0.06485985964536667)\n",
      "(295, 0.06211329996585846)\n",
      "(296, 0.05951397120952606)\n",
      "(297, 0.05702374875545502)\n",
      "(298, 0.054630570113658905)\n",
      "(299, 0.05233990401029587)\n",
      "(300, 0.05014578625559807)\n",
      "(301, 0.04804179072380066)\n",
      "(302, 0.04604734852910042)\n",
      "(303, 0.0441257543861866)\n",
      "(304, 0.042270272970199585)\n",
      "(305, 0.040502384305000305)\n",
      "(306, 0.038805440068244934)\n",
      "(307, 0.03719174489378929)\n",
      "(308, 0.035652246326208115)\n",
      "(309, 0.034171056002378464)\n",
      "(310, 0.032743748277425766)\n",
      "(311, 0.031385622918605804)\n",
      "(312, 0.030080772936344147)\n",
      "(313, 0.028823720291256905)\n",
      "(314, 0.027621187269687653)\n",
      "(315, 0.026471048593521118)\n",
      "(316, 0.02538236416876316)\n",
      "(317, 0.024328557774424553)\n",
      "(318, 0.023330286145210266)\n",
      "(319, 0.02236960455775261)\n",
      "(320, 0.021453702822327614)\n",
      "(321, 0.02056669257581234)\n",
      "(322, 0.019719848409295082)\n",
      "(323, 0.018905064091086388)\n",
      "(324, 0.01811812072992325)\n",
      "(325, 0.01737169362604618)\n",
      "(326, 0.016666164621710777)\n",
      "(327, 0.015977922827005386)\n",
      "(328, 0.015327643603086472)\n",
      "(329, 0.014697260223329067)\n",
      "(330, 0.014106940478086472)\n",
      "(331, 0.013524424284696579)\n",
      "(332, 0.012971144169569016)\n",
      "(333, 0.012442585080862045)\n",
      "(334, 0.011931728571653366)\n",
      "(335, 0.011454096995294094)\n",
      "(336, 0.010984200052917004)\n",
      "(337, 0.010538614355027676)\n",
      "(338, 0.010111575946211815)\n",
      "(339, 0.009705687873065472)\n",
      "(340, 0.009316854178905487)\n",
      "(341, 0.008938394486904144)\n",
      "(342, 0.008578515611588955)\n",
      "(343, 0.00824176799505949)\n",
      "(344, 0.007903553545475006)\n",
      "(345, 0.0075863441452383995)\n",
      "(346, 0.0072906529530882835)\n",
      "(347, 0.006998698227107525)\n",
      "(348, 0.006723901256918907)\n",
      "(349, 0.006457374896854162)\n",
      "(350, 0.006207671482115984)\n",
      "(351, 0.005963832139968872)\n",
      "(352, 0.005726103205233812)\n",
      "(353, 0.005497361999005079)\n",
      "(354, 0.005279393866658211)\n",
      "(355, 0.005075835157185793)\n",
      "(356, 0.004881876055151224)\n",
      "(357, 0.0046957191079854965)\n",
      "(358, 0.004512915387749672)\n",
      "(359, 0.004339096136391163)\n",
      "(360, 0.004171579144895077)\n",
      "(361, 0.004008577670902014)\n",
      "(362, 0.003858342068269849)\n",
      "(363, 0.0037122154608368874)\n",
      "(364, 0.0035704784095287323)\n",
      "(365, 0.0034368925262242556)\n",
      "(366, 0.0033073348458856344)\n",
      "(367, 0.003183959051966667)\n",
      "(368, 0.003066164208576083)\n",
      "(369, 0.002952640876173973)\n",
      "(370, 0.0028424959164112806)\n",
      "(371, 0.0027368138544261456)\n",
      "(372, 0.002638527425006032)\n",
      "(373, 0.002539168344810605)\n",
      "(374, 0.0024468707852065563)\n",
      "(375, 0.0023587029427289963)\n",
      "(376, 0.002273296471685171)\n",
      "(377, 0.0021913917735219)\n",
      "(378, 0.0021140743046998978)\n",
      "(379, 0.0020385889802128077)\n",
      "(380, 0.0019668685272336006)\n",
      "(381, 0.001897771144285798)\n",
      "(382, 0.0018341427203267813)\n",
      "(383, 0.0017697577131912112)\n",
      "(384, 0.0017051027389243245)\n",
      "(385, 0.0016502614598721266)\n",
      "(386, 0.0015889242058619857)\n",
      "(387, 0.0015363857382908463)\n",
      "(388, 0.001485183252952993)\n",
      "(389, 0.0014336812309920788)\n",
      "(390, 0.0013854351127520204)\n",
      "(391, 0.0013401308096945286)\n",
      "(392, 0.001297523151151836)\n",
      "(393, 0.0012536639114841819)\n",
      "(394, 0.0012132091214880347)\n",
      "(395, 0.0011713093845173717)\n",
      "(396, 0.0011356057366356254)\n",
      "(397, 0.001097336527891457)\n",
      "(398, 0.0010623253183439374)\n",
      "(399, 0.0010272981598973274)\n",
      "(400, 0.0009962787153199315)\n",
      "(401, 0.0009635321912355721)\n",
      "(402, 0.0009323562262579799)\n",
      "(403, 0.00090410141274333)\n",
      "(404, 0.000875870231539011)\n",
      "(405, 0.0008481484255753458)\n",
      "(406, 0.0008216846035793424)\n",
      "(407, 0.0007966927951201797)\n",
      "(408, 0.0007740596774965525)\n",
      "(409, 0.0007480823551304638)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 0.0007258341065607965)\n",
      "(411, 0.0007044964004307985)\n",
      "(412, 0.0006840134155936539)\n",
      "(413, 0.0006625623791478574)\n",
      "(414, 0.0006451128283515573)\n",
      "(415, 0.0006267348071560264)\n",
      "(416, 0.0006074779666960239)\n",
      "(417, 0.0005909196916036308)\n",
      "(418, 0.0005732661811634898)\n",
      "(419, 0.0005565555184148252)\n",
      "(420, 0.0005403372342698276)\n",
      "(421, 0.0005241833860054612)\n",
      "(422, 0.0005093888030387461)\n",
      "(423, 0.0004956190823577344)\n",
      "(424, 0.00048256496665999293)\n",
      "(425, 0.0004690308414865285)\n",
      "(426, 0.0004565826093312353)\n",
      "(427, 0.0004437913012225181)\n",
      "(428, 0.0004318080027587712)\n",
      "(429, 0.0004207433375995606)\n",
      "(430, 0.00040918102604337037)\n",
      "(431, 0.0003985745133832097)\n",
      "(432, 0.00038796354783698916)\n",
      "(433, 0.00037862619501538575)\n",
      "(434, 0.0003692866594064981)\n",
      "(435, 0.0003596935130190104)\n",
      "(436, 0.0003500572929624468)\n",
      "(437, 0.00034045788925141096)\n",
      "(438, 0.00033315172186121345)\n",
      "(439, 0.0003245194675400853)\n",
      "(440, 0.00031606602715328336)\n",
      "(441, 0.00030824457644484937)\n",
      "(442, 0.0003005155303981155)\n",
      "(443, 0.0002934553485829383)\n",
      "(444, 0.00028649301384575665)\n",
      "(445, 0.0002789008431136608)\n",
      "(446, 0.0002729467523749918)\n",
      "(447, 0.0002659895399119705)\n",
      "(448, 0.0002601662708912045)\n",
      "(449, 0.0002542267320677638)\n",
      "(450, 0.0002480480761732906)\n",
      "(451, 0.0002424271369818598)\n",
      "(452, 0.0002365514519624412)\n",
      "(453, 0.0002309275878360495)\n",
      "(454, 0.0002261947956867516)\n",
      "(455, 0.00022101459035184234)\n",
      "(456, 0.0002153334062313661)\n",
      "(457, 0.0002103424776578322)\n",
      "(458, 0.00020522692648228258)\n",
      "(459, 0.0002008791925618425)\n",
      "(460, 0.00019686826271936297)\n",
      "(461, 0.0001927089033415541)\n",
      "(462, 0.00018865011224988848)\n",
      "(463, 0.00018396576342638582)\n",
      "(464, 0.00018072084640152752)\n",
      "(465, 0.00017676022252999246)\n",
      "(466, 0.0001729862706270069)\n",
      "(467, 0.00016922640497796237)\n",
      "(468, 0.00016616139328107238)\n",
      "(469, 0.00016244585276581347)\n",
      "(470, 0.00015925387560855597)\n",
      "(471, 0.00015643240476492792)\n",
      "(472, 0.00015292011084966362)\n",
      "(473, 0.00015004123270045966)\n",
      "(474, 0.00014677690342068672)\n",
      "(475, 0.00014388724230229855)\n",
      "(476, 0.0001413635181961581)\n",
      "(477, 0.0001385035429848358)\n",
      "(478, 0.00013606628635898232)\n",
      "(479, 0.00013304612366482615)\n",
      "(480, 0.0001304744801018387)\n",
      "(481, 0.00012812296336051077)\n",
      "(482, 0.0001253454975085333)\n",
      "(483, 0.00012315278581809253)\n",
      "(484, 0.0001203009596792981)\n",
      "(485, 0.00011811457807198167)\n",
      "(486, 0.0001159049425041303)\n",
      "(487, 0.00011380741489119828)\n",
      "(488, 0.00011136011744383723)\n",
      "(489, 0.00010942586959572509)\n",
      "(490, 0.00010806654609041288)\n",
      "(491, 0.00010592319449642673)\n",
      "(492, 0.00010409157403046265)\n",
      "(493, 0.00010251387720927596)\n",
      "(494, 0.00010086050315294415)\n",
      "(495, 9.894702088786289e-05)\n",
      "(496, 9.712456085253507e-05)\n",
      "(497, 9.519479499431327e-05)\n",
      "(498, 9.353808127343655e-05)\n",
      "(499, 9.193339064950123e-05)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# 若需要运行在GPU上则取消下一行的注释\n",
    "# dtype = torch.cuda.FloatTensor\n",
    "\n",
    "# N     ：样本的数量，本例采用批量梯度下降，每次训练使用全部的样本\n",
    "# D_in  ：输入特征的维度\n",
    "# H     ：隐层神经元的数量\n",
    "# D_out ：输出层维度\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 创建保存输入和输出的随机张量，并将张量封装到Variable当中\n",
    "# 设置 requires_grad=Flase 意味着在反向传播的过程中，不需要计算关于x和y的梯度\n",
    "x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# 创建存储权重的随机张量，并将它们封装到Variable当中\n",
    "# 设置 requires_grad=True，意味着在反向传播的过程中，需要计算关于w1和w2的梯度\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n",
    "\n",
    "# 设置学习率\n",
    "learning_rate = 1e-6\n",
    "\n",
    "# 存储训练过程的loss\n",
    "losses = []\n",
    "\n",
    "for t in range(500):\n",
    "    # 前向传播：用Variable的运算来计算预测的y值；\n",
    "    # 这与用Tensor实现的前向传播从本质上是一样的，但是由于不需要手动实现反向传播，\n",
    "    # 因此不需要保持对中间变量的引用。\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    # 用Variable支持的运算，计算并输出loss。\n",
    "    # loss是一个形状为(1,)，loss.data是一个形状为(1,)的张量。\n",
    "    # 因此loss.data[0]存储loss的标量值。\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.data[0])\n",
    "    \n",
    "    # 存储损失\n",
    "    losses.append(loss.data[0])\n",
    "    \n",
    "    # 使用autograd来计算反向传播。调用backward将计算loss关于需要求导的变量的梯度，\n",
    "    # 通过设置requires_grad=True来设置变量需要求导。\n",
    "    # 调用完成之后，变量（Variable）w1.grad和w2.grad将分别保存loss关于w1和w2的梯度\n",
    "    loss.backward()\n",
    "    \n",
    "    # 用梯度下降算法更新权重。\n",
    "    # w1.grad和w2.grad是变量（Variable），而w1.grad.data和w2.grad.data是张量\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "    \n",
    "    # 更新权重后，要将梯度手工清零\n",
    "    # 因为backward过程是将新计算出来的梯度累加到现存的梯度上。\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCRIKfBGRIKHAFxEJEgp8EZEg8f8duVp9VHiofwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc80ce8b850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.plot(np.log(np.array(losses)))\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
